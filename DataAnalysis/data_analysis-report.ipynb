{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# After extracting the data from Amazon using scrapy, we have stored the data into a simple json text file.\n",
    "# Importing the data from the json text file into a pandas dataframe:\n",
    "amazon_data = pd.read_json('/home/adelo/amazon_data.json')\n",
    "\n",
    "amazon_data[['ASIN','price','average_customer_reviews','number_reviews','number_ratings','tech_details','reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# After extracting the data from Amazon using scrapy, we have stored the data into a simple json text file.\n",
    "# Importing the data from the json text file into a pandas dataframe:\n",
    "amazon_data = pd.read_json('/home/adelo/amazon_data.json')\n",
    "\n",
    "\n",
    "# After loading the data from the json file, every «review» entry is a dictionary type value that is composed of several fields: customer name, rating, date, title, and the text of the review itself.\n",
    "# Here we extract the relevant details (title and the text of the review itself) and create 3 new \n",
    "# columns to facilitate the handling of the «review» entries. We create the following columns: «reviews_title», «reviews_text» and «reviews_one_string»:\n",
    "reviews_title = []\n",
    "reviews_text  = []\n",
    "reviews_one_string = []\n",
    "for i in range(amazon_data.shape[0]):\n",
    "    reviews_title_per_item = []\n",
    "    reviews_text_per_item  = []\n",
    "    reviews_one_string_per_item = ''\n",
    "    for j in range(len(amazon_data['reviews'][i])):\n",
    "        title = amazon_data['reviews'][i][j]['title']\n",
    "        text  = amazon_data['reviews'][i][j]['review_text']\n",
    "        reviews_title_per_item.append(title)\n",
    "        reviews_text_per_item.append(text)\n",
    "        reviews_one_string_per_item += title+' '+text+' '\n",
    "    reviews_title.append(reviews_title_per_item)\n",
    "    reviews_text.append(reviews_text_per_item)\n",
    "    reviews_one_string.append(reviews_one_string_per_item.rstrip())\n",
    "\n",
    "# reviews_title is a list that contains all review titles in a review entry:\n",
    "amazon_data['reviews_title'] = reviews_title\n",
    "# reviews_text is a list that contains all review comments (without the title)\n",
    "# in a review entry:\n",
    "amazon_data['reviews_text']  = reviews_text\n",
    "# reviews_text is a list that contains all review comments (including the title) in a review entry:\n",
    "amazon_data['reviews_one_string']  = reviews_one_string\n",
    "\n",
    "\n",
    "# Here we make sure that the first character of the brand name is uppercase and \n",
    "# remaining characters lowercase. This is important because we are going to perform\n",
    "# filtering and searching function using the brand name so we need to make sure \n",
    "# that the writing is consistent.\n",
    "amazon_data['brand'] = [ amazon_data['tech_details'][i]['Brand Name'].title()  if   amazon_data\n",
    "['tech_details'][i]['Brand Name'] not in ['HP','hp','Hp']  else    amazon_data['tech_details'][i]['Brand Name'].upper()  for  i  in range(amazon_data.shape[0]) ]\n",
    "\n",
    "\n",
    "# After loading the data from the json file, all technical details are in a dictionary type entry.\n",
    "# In the following block we are extracting the tech details that are important for our analysis («series» and «model_number») and creating new columns for each of these relevant tech details\n",
    "# Series:\n",
    "amazon_data['series'] = [ amazon_data['tech_details'][i]['Series']  for  i  in  range(amazon_data.shape[0]) ]\n",
    "# Model number:\n",
    "amazon_data['model_number'] = [ amazon_data['tech_details'][i]['Item model number']  for  i  in  range(amazon_data.shape[0]) ]\n",
    "\n",
    "\n",
    "# After extracting the data from the web page, the numeric values (\"average_customer_reviews\" and \"price\") are actually of «string» type. So, We need to convert the entry to a numeric type (Float). This is necessary because we will perform mathematical operations with these values:\n",
    "\n",
    "# The following function takes a numeric string (<class 'str'>), removes any comma or dollar characters (\",\" \"$\") and\n",
    "# returns a numeric float value (<class 'float'>):\n",
    "def format_cleaner(entry):\n",
    "    return float(entry.replace(',','').replace('$',''))\n",
    "\n",
    "# A raw «average_customer_reviews» entry looks like this: \"4.5 out of 5 stars\"  (<class 'str'>)\n",
    "# We only need the firs value as a numeric float type: 4.5  (<class 'float'>)\n",
    "# This is done in the next line of code over the entire dataframe by selecting only the \n",
    "# firs element (\"4.5\" in the above example) and applying the «format_cleaner()» function to the «average\\_customer\\_reviews» column:\n",
    "amazon_data['average_customer_reviews'] = [ format_cleaner(val[0]) for val in amazon_data['average_customer_reviews'].str.split() ]\n",
    "\n",
    "# A raw «price» entry looks like this: \"$689.90\"  (<class 'str'>)\n",
    "# We only need the numeric value: 689.90  (<class 'float'>)\n",
    "# This is done in the next line of code over the entire dataframe by applying the «format_cleaner()» function to the «price» column:\n",
    "amazon_data['price'] = amazon_data['price'].apply(lambda val: round(format_cleaner(val)) if pd.notnull(val) else val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionando (en orden de importancia) las columnas más relevantes for our analysis:\n",
    "cols = ['brand','series','model_number','price','average_customer_reviews','number_reviews','number_ratings','reviews_title','reviews_text','reviews_one_string','url']\n",
    "amazon_data = amazon_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.data.path.append('/home/adelo/.nltk/nltk_data')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Removing punctuation and stopwords:\n",
    "# * Punctuation: We will remove all punctuation char found the «string» library.\n",
    "# * Our stopwords will be composed by:\n",
    "#   - The common stopwords defined in the nltk library \n",
    "#   - Some particular stopwords related to our data:\n",
    "#     * Brand names: There is no point in analyzing brand names. For instance, in a Lenovo review, the customer will use the word ``Lenovo'' many times, but this fact does not contribute anything to the analysis. \n",
    "#     * Laptop synonyms: laptop, computer, machine, etc.\n",
    "#     * Some no-official contractions that are not in the nltk library: Im dont Ive, etc.\n",
    "\n",
    "# Defining our stopwords list:\n",
    "import nltk\n",
    "import string\n",
    "nltk.data.path.append('/home/adelo/.nltk/nltk_data')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_brands = [ b.lower() for b in list(set(amazon_data['brand'])) ]\n",
    "stopwords_brands_additionals = ['computer','computers','laptop','laptops','thing','things','machine','machines','im','dont','ive']\n",
    "stopwords_total  = stopwords.words('english') + stopwords_brands + stopwords_brands_additionals\n",
    "\n",
    "# The following function takes a string and returns the same string without punctuation or stopwords:\n",
    "def pre_processing(texto):\n",
    "    # Removing punctuation:\n",
    "    nopunct = ''.join([ char for char in texto if char not in string.punctuation ])\n",
    "    # Removing Stopwords:\n",
    "    return ' '.join([ word for word in nopunct.split() if word.lower() not in stopwords_total ])\n",
    "\n",
    "# Example of applying the function «pre_processing()»:\n",
    "frase = \"Here! A sentence: It has $SOME punctuation and stopwords...\"\n",
    "frase_clean = pre_processing(frase)\n",
    "frase_clean\n",
    "\n",
    "# Here we are applying the function «pre_processing()» to the «reviews_one_string» column over the entire dataframe:\n",
    "amazon_data['reviews_one_string'] = amazon_data['reviews_one_string'].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(amazon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_data.to_json(r'./data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json('./data.json')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "TextBlob('I am great but the impotant thing is that I am not undarstanding what I have to do but I am not loving it ok and it is really bad bad bad bad bad bad bad bad bad bad lov').sentiment\n",
    "\n",
    "TextBlob(data['reviews_one_string'].loc[1]).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda11de9112d84a49afbbf20f955bb49b93",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}